# -*- coding: utf-8 -*-
"""Semana-i-neoris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-u6YrKGDmvNTDjDH0nls8Cq0BNItqoZY

# Semana i
"""

!pip install prophet

!pip install cufflinks
!pip install plotly --upgrade
!pip install chart_studio
!pip install opendatasets
!pip install jupyter-dash

# Commented out IPython magic to ensure Python compatibility.
# Python
import pandas as pd
from prophet import Prophet
import datetime
import matplotlib.pyplot as plt 
from matplotlib.pyplot import figure
from IPython.display import HTML
import plotly.express as px
import plotly.graph_objects as go
import glob
from prophet.diagnostics import performance_metrics
from prophet.diagnostics import cross_validation
import cufflinks as cf
from prophet.plot import plot_plotly, plot_components_plotly
from sklearn.metrics import mean_squared_error
import numpy as np
import itertools 
# %matplotlib inline

from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot 
init_notebook_mode(connected = True)
cf.go_offline()

def enable_plotly_in_cell():
  import IPython
  from plotly.offline import init_notebook_mode
  display(IPython.core.display.HTML('''<script src="/static/components/requirejs/require.js"></script>'''))
  init_notebook_mode(connected=False)

stores = []

path = r'/content/' # use your path
all_files = glob.glob(path + "/*.parquet.gzip")

for filename in all_files:
    df = pd.read_parquet(filename)
    stores.append(df)

"""## Limpieza de Datos

"""

def dataCleaning():
  for store in stores:
    store.drop(['SALES_DIST','SOLD_TO','SHIP_TO','MATERIAL'],inplace=True,axis=1)

dataCleaning()

enable_plotly_in_cell()
for store in stores:
  fig = px.scatter(store,y='PIEZAS',x='BILL_DATE')
  fig.show()

#start_date = '2019-09-01'
#end_date = '2019-09-30'
#mask = (df['BILL_DATE'] > start_date) & (df['BILL_DATE'] <= end_date)
#df_tmp = df.loc[mask]
#september_mean = df_tmp.groupby('BILL_DATE',dropna=True)["PIEZAS"].sum().mean()
#print(september_mean)

start_date = '2020-09-01'
end_date = '2020-09-30'
mask = (df['BILL_DATE'] > start_date) & (df['BILL_DATE'] <= end_date)
df_tmp = df.loc[mask]
september_mean2 = df_tmp.groupby('BILL_DATE',dropna=True)["PIEZAS"].sum().mean()
print(september_mean2)

#df.between_time('2019-09-01', '2019-09-30')
aux= pd.date_range("2019-10-01", periods = 31, freq = "D")
aux2= pd.date_range("2020-10-01", periods = 31, freq = "D")
ser = pd.DataFrame(data=aux,columns=['BILL_DATE'])
ser['PIEZAS'] = september_mean
ser2 = pd.DataFrame(data=aux2,columns=['BILL_DATE'])
ser2['PIEZAS'] = september_mean2
print(ser)

df_day = []
def Dfgroupby():
  for store in stores:
    df_day.append(store.groupby('BILL_DATE',dropna=True, as_index=False)["PIEZAS"].sum())

Dfgroupby()

lis = [df_day,ser,ser2]
df_tmp2 = pd.concat(lis)
df_tmp2.sort_values(by='BILL_DATE',inplace=True)
df_tmp2
df_train = df_tmp2[:int(len(df_tmp2)*0.6)]
df_validation = df_tmp2[int(len(df_tmp2)*0.6):int(len(df_tmp2)*0.8)]
df_test = df_tmp2[int(len(df_tmp2)*0.8):]

print(df_train.shape,df_validation.shape,df_test.shape)

print(df.shape)

enable_plotly_in_cell()
for store in df_day:
  fig = px.line(store,y='PIEZAS',x='BILL_DATE')
  fig.show()

def changeColumnName():
  for store in df_day:
    store.columns = ['ds','y']

#df_train.columns = ['ds','y']
#df_validation.columns = ['ds','y']
#df_test.columns = ['ds','y']
#df_train.head()

changeColumnName()

enable_plotly_in_cell()
models = []
futures = []
forecasts = []
def makeModels():
  for store in df_day:
    models.append(Prophet())
    models[-1].fit(store)
    futures.append(models[-1].make_future_dataframe(periods=7))
    futures[-1].tail(7)
    forecasts.append(models[-1].predict(futures[-1]))
    #forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)
    #plot_plotly(m,forecast)

enable_plotly_in_cell()
makeModels()

enable_plotly_in_cell()
for x in range(7):
  plot_plotly(models[x],forecasts[x])

enable_plotly_in_cell()
plot_plotly(models[0],forecasts[0])

enable_plotly_in_cell()
plot_plotly(models[1],forecasts[1])

enable_plotly_in_cell()
plot_plotly(models[2],forecasts[2])

enable_plotly_in_cell()
plot_plotly(models[3],forecasts[3])

enable_plotly_in_cell()
plot_plotly(models[4],forecasts[4])

enable_plotly_in_cell()
plot_plotly(models[5],forecasts[5])

enable_plotly_in_cell()
plot_plotly(models[6],forecasts[6])

plot_components_plotly(m,forecast)

df_day[1].shape

df_cv = cross_validation(models[1], initial='300 days', period='30 days', horizon = '7 days')
df_cv.head()

df_p = performance_metrics(df_cv)
df_p.head(10)

meanValue = df_day[0].mean()
lis = [meanValue] * 225
lis2 = df_day[0]['y'].tolist()
rms = mean_squared_error(lis2, lis, squared=False)
rms

param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],
    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],
}

# Generate all combinations of parameters
all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]
rmses = []  # Store the RMSEs for each params here

# Use cross validation to evaluate all parameters
for params in all_params:
    m = Prophet(**params).fit(df_day[0])  # Fit model with given params
    df_cv = cross_validation(m, initial='150 days', period='30 days', horizon = '7 days', parallel='processes')
    df_p = performance_metrics(df_cv)
    rmses.append(df_p['rmse'].values[0])

# Find the best parameters
tuning_results = pd.DataFrame(all_params)
tuning_results['rmse'] = rmses
print(tuning_results)

best_params = all_params[np.argmin(rmses)]
print(best_params)

from prophet.plot import plot_cross_validation_metric
fig = plot_cross_validation_metric(df_cv, metric='mape')